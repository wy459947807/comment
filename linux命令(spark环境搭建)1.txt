二、设置IP地址、网关DNS
说明：CentOS 7.0默认安装好之后是没有自动开启网络连接的！
cd  /etc/sysconfig/network-scripts/  #进入网络配置文件目录

vi  ifcfg-eno16777736  #编辑配置文件，添加修改以下内容

ONBOOT=yes  #开启自动启用网络连接

TYPE=Ethernet
BOOTPROTO=static
DEFROUTE=yes
PEERDNS=yes
PEERROUTES=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_PEERDNS=yes
IPV6_PEERROUTES=yes
IPV6_FAILURE_FATAL=no
NAME=enp0s3
UUID=4f7ebebe-b495-40d4-866d-3a9a47419c65
DEVICE=enp0s3
ONBOOT=yes
IPADDR=192.168.131.240 
GATEWAY=192.168.131.1 
NETMASK=255.255.255.0
DNS1=192.168.131.1 


按任意键进入编辑
Esc键结束编辑

:wq!  #保存退出

:q!  #强制退出
 
service network restart   #重启网络
ping www.baidu.com  #测试网络是否正常

ctrl+c结束当前程序返回命令行
ctrl+PageUp命令行翻页


yum install net-tools Cy    ----安装netstat工具



ifconfig ----查看ip信息


yum instatll net-tools Cy    ----安装netstat工具


linux安装JDK http://blog.csdn.net/yttcjj/article/details/6974161
1、先从网上下载jdk(jdk-7u1-linux-i586.rpm)，放在/home目录中
2、进入安装目录
#cd /home
#cp jdk-7u1-linux-i586.rpm /usr/local
#cd /usr/local
给所有用户添加可执行的权限
#rpm -ivh jdk-7u1-linux-i586.rpm

3、设置环境变量

#vi /etc/profile

在里面添加如下内容

export JAVA_HOME=/usr/java/jdk1.8.0_111
export SCALA_HOME=/usr/scala-2.12.1
export SPARK_HOME=/usr/spark-2.1.0-bin-hadoop2.7
export HADOOP_HOME=/usr/hadoop-2.7.3

export JAVA_BIN=/usr/java/jdk1.8.0_111/bin
export PATH=$PATH:$JAVA_HOME/bin:$SCALA_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$HADOOP_HOME/bin
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export JAVA_HOME JAVA_BIN PATH CLASSPATH


让/etc/profile文件修改后立即生效 ,可以使用如下命令:

# . /etc/profile
注意: . 和 /etc/profile 有空格.
重启测试

java -version


spark安装：
解压：

tar zxvf scala-2.11.4.tgz

tar zxvf spark-1.2.0-bin-hadoop2.4.tgz


vim /etc/profile

加上以下对应内容：

export JAVA_HOME=/home/yy/jdk1.8

export SCALA_HOME=/home/yy/scala

export SPARK_HOME=/home/yy/spark-1.2.0-bin-hadoop2.4

export PATH=$PATH:$JAVA_HOME/bin:$SCALA_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin

执行source /etc/profile使配置生效

修改spark配置

进入spark-1.2.0-bin-hadoop2.4/conf

复制模板文件：

cp spark-env.sh.template spark-env.sh

cp slaves.template slaves

编辑spark-env.sh

添加上你的对应信息：

export JAVA_HOME=/usr/java/jdk1.8.0_111

export SCALA_HOME=/usr/scala-2.12.1

export SPARK_MASTER_IP=192.168.131.157

export SPARK_WORKER_MEMORY=2g

export HADOOP_CONF_DIR=/usr/hadoop-2.7.3/etc/hadoop

编辑slaves

添加上你的对应信息，所有的集群的机器：

192.168.131.157

192.168.131.43

192.168.131.240
到此为止，前面所有的安装配置动作，在你的另一个机器上(所有的slave机器)同样的做一遍，即我这里的205机器

进入spark-1.2.0-bin-hadoop2.4/sbin/目录

执行：./start-all.sh

如果没有设置ssh免密码登陆，会要求输入密码

这时候jps查看多了个master和worker

浏览器查看集群信息

master地址+8080端口

启动Running Applications

在bin目录下执行：

 MASTER=spark://172.20.0.204:7077 ./spark-shell

这时候就可以看到运行的app啦

同时可以查看jobs内容：
http://172.20.0.204:4040/jobs/

slave机器上也运行app，这时候就可以看到运行的applications有两个啦。

好了，环境就算先搭起来啦，后面就是去调用吧。

hadoop环境搭建

永久修改主机名：

修改/etc/sysconfig/network中的hostname

vi /etc/sysconfig/network
HOSTNAME=localhost.localdomain  #修改localhost.localdomain为orcl1

2.配置hosts文件

修改集群中所有机器的/etc/hosts，打开该文件的命令如下：

sudo gedit /etc/hosts

添加：

192.168.131.157 master
192.168.131.43  slave
192.168.131.240 slave1

tar xzfv hadoop-2.6.0.tar.gz


（2）.配置Hadoop

1.修改hadoop-2.6.0/etc/hadoop/hadoop-env.sh，添加JDK支持：

export JAVA_HOME=/usr/java/jdk1.8.0_25

如果不知道你的JDK目录，使用命令echo $JAVA_HOME查看。

2.修改hadoop-2.6.0/etc/hadoop/core-site.xml

注意：必须加在<configuration></configuration>节点内

<configuration>
<property>
        <name>hadoop.tmp.dir</name>
        <value>/home/hadoop/hadoop-2.6.0/tmp</value>
        <description>Abase for other temporary directories.</description>
    </property>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://master:9000</value>
    </property>
</configuration>

3.修改hadoop-2.6.0/etc/hadoop/hdfs-site.xml

<property>
    <name>dfs.name.dir</name>
    <value>/home/hadoop/hadoop-2.6.0/dfs/name</value>
    <description>Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently.</description>
</property>
 
<property>
    <name>dfs.data.dir</name>
    <value>/home/hadoop/hadoop-2.6.0/dfs/data</value>
    <description>Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks.</description>
</property>
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>

4.修改hadoop-2.6.0/etc/hadoop/mapred-site.xml

<property>
    <name>mapred.job.tracker</name>
    <value>master:9001</value>
    <description>Host or IP and port of JobTracker.</description>
</property>

5. 修改hadoop-2.6.0/etc/hadoop/masters

列出所有的master节点：

master

6.修改hadoop-2.6.0/etc/hadoop/slaves

这个是所有datanode的机器，例如：

slave1

slave2

slave3

slave4

7.将master结点上配置好的hadoop文件夹拷贝到所有的slave结点上

以slave1为例：命令如下：

scp -r  ~/hadoop-2.6.0 hadoop@slave1:~/

安装完成后，我们要格式化HDFS然后启动集群所有节点。

5.启动Hadoop

1.格式化HDFS文件系统的namenode

（这里要进入hadoop-2.6.0目录来格式化好些）：

cd hadoop-2.6.0  //进入hadoop-2.6.0目录

bin/hdfs namenode -format  //格式化

2.启动Hadoop集群
启动hdrs命令如下：

sbin/start-all.sh //开启进程

我们也可以通过网页来看是否正常安装与配置，地址如下：http://master:50070/


echo "1" > /usr/zookeeper-3.4.6/tmp/myid

http://blog.csdn.net/erfucun/article/details/52343957
http://m.blog.csdn.net/article/details?id=50316383  //开发环境
http://www.cnblogs.com/tovin/p/3822985.html //打包
http://www.jianshu.com/p/a617005df355 //dome
http://www.csdn.net/article/2010-11-29/282674 //ndfs文件系统
http://www.cnblogs.com/liping13599168/archive/2011/04/15/2017369.html
http://pan.baidu.com/s/1i3lGfZn 密码: r6vh //视频地址
http://www.cnblogs.com/luotianshuai/p/5206662.html //kafka
http://blog.csdn.net/a237428367/article/details/50464153 //免登录